{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-groq\n",
    "%pip install -qU langchain-groq\n",
    "%pip install -U langgraph\n",
    "%pip install spotipy\n",
    "%pip install -qU langchain-google-genai\n",
    "#SET UP THE ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
    "    #  gemini_api = AIzaSyBg08xM6oJslFh3Ske_2SfTRdrRDx7pp7I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHAT-MODEL SETUP\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    "    # check invokation here\n",
    ")\n",
    "#  llm.invoke(\"Hello\")\n",
    "\n",
    "# Spotify Authentication\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.tools import Tool\n",
    "\n",
    "\n",
    "\n",
    "SCOPE = \"playlist-modify-public playlist-read-private playlist-modify-private\"\n",
    "sp_oauth = SpotifyOAuth(\n",
    "    client_id=\"b8b719e778c2490fa3401ac44ef6c0d6\",  # Replace with your credentials\n",
    "    client_secret=\"e8f4d474f858432da3e4002eba2ab7fe\",\n",
    "    redirect_uri=\"http://localhost:8888/callback\",\n",
    "    scope=SCOPE,\n",
    ")\n",
    "_sp = spotipy.Spotify(auth_manager=sp_oauth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spotipy.client.Spotify'>\n"
     ]
    }
   ],
   "source": [
    "print(type(_sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict, Annotated, Any\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.managed import IsLastStep\n",
    "from operator import add\n",
    "\n",
    "\n",
    "\n",
    "# STATE INITIALISATION:\n",
    "\n",
    "class SpotifyState(TypedDict):\n",
    "\n",
    "    messages : Annotated[list,add_messages]\n",
    "    messages_2: Annotated[list, add_messages]\n",
    "    all_playlist: list[dict]\n",
    "    is_last_step: IsLastStep\n",
    "    remaining_steps: Any\n",
    "    # is_last_step and remaining_steps : were required by the pre-build create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Rap it up!!', 'id': '1hutKN3PVaquuA7PmS2Khm'}, {'name': 'Electronic', 'id': '5dO3GrkDYgeek1xTUd252i'}]\n"
     ]
    }
   ],
   "source": [
    "#logic to display all playlist in spotify acoount\n",
    "playlist_list = []\n",
    "\n",
    "results = _sp.current_user_playlists(limit=10)\n",
    "\n",
    "while results:  # Check if results is not None\n",
    "    if 'items' in results: #check if results has items key\n",
    "        for playlist in results['items']:\n",
    "            playlist_list.append({\"name\": playlist['name'], \"id\": playlist['id']})\n",
    "\n",
    "        if results['next']:\n",
    "            results = _sp.next(results)\n",
    "        else:\n",
    "            results = None  # Explicitly set results to None when done\n",
    "    else:\n",
    "        results = None #if there are no items key, set results to none to break the loop\n",
    "\n",
    "\n",
    "print(playlist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NODE - 1\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "#returns all playlist of the user in this node and the updates are sent to the state \n",
    "# the state will now have all the playlist and playlist_id \n",
    "#access state['all_playlist'] to see a List[dict] type to see playlist name and id\n",
    "\n",
    "def show_playlist(state: SpotifyState):\n",
    "    playlist_list = []\n",
    "    messages=state['messages']\n",
    "\n",
    "    results = _sp.current_user_playlists(limit=5)\n",
    "\n",
    "    while results:  # Check if results is not None\n",
    "        if 'items' in results: #check if results has items key\n",
    "            for playlist in results['items']:\n",
    "                playlist_list.append({\"name\": playlist['name'], \"id\": playlist['id']})\n",
    "\n",
    "            if results['next']:\n",
    "                results = _sp.next(results)\n",
    "            else:\n",
    "                results = None  # Explicitly set results to None when done\n",
    "        else:\n",
    "            results = None #if there are no items key, set results to none to break the loop\n",
    "       \n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]  ,'all_playlist' : playlist_list, \"is_last_step\" : False}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPROACH 1 : \n",
    " CREATING TOOLS WITH A PYDANTIC CLASS TO STORE TOOLS_ARGS AND BINDING TO THE PRE-BUILT CREATE_REACT_AGENT: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, TypedDict, Annotated, Any\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.managed import IsLastStep\n",
    "from langchain_core.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.tools import Tool\n",
    "from pydantic import BaseModel,Field, PrivateAttr\n",
    "\n",
    "#sp Creation for Oauth\n",
    "SCOPE = \"playlist-modify-public playlist-read-private playlist-modify-private\"\n",
    "sp_oauth = SpotifyOAuth(\n",
    "    client_id=\"b8b719e778c2490fa3401ac44ef6c0d6\",  # Replace with your credentials\n",
    "    client_secret=\"e8f4d474f858432da3e4002eba2ab7fe\",\n",
    "    redirect_uri=\"http://localhost:8888/callback\",\n",
    "    scope=SCOPE\n",
    ")\n",
    "sp = spotipy.Spotify(auth_manager=sp_oauth)\n",
    "\n",
    "#llm set-up\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    "    # check invokation here\n",
    ")\n",
    "\n",
    "# STATE INITIALISATION:\n",
    "\n",
    "class SpotifyState(TypedDict):\n",
    "\n",
    "    messages : Annotated[list,add_messages]\n",
    "    all_playlist: list[dict]\n",
    "    is_last_step: IsLastStep\n",
    "    remaining_steps: Any\n",
    "    token: Any\n",
    "\n",
    "\n",
    "#Pydantic class to specify all args that can be used by the tools, including the \"sp\" access_token \n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Any, List\n",
    "\n",
    "class PlaylistItem(BaseModel):\n",
    "    name: str = Field(..., description=\"Name of the playlist\")\n",
    "    id: str = Field(..., description=\"Playlist ID\")\n",
    "    \n",
    "    class Config:\n",
    "        extra = \"forbid\"\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "class ShowAllPlaylist(BaseModel):\n",
    "    _sp: Any = PrivateAttr(default=sp)  # your Spotify client, PRIVATE: cz, not included in JSON parsing\n",
    "    query: str = Field(..., description=\"Search query for tracks\")\n",
    "    song_name: str = Field(..., description=\"Name of the song\")\n",
    "    artist_name: str = Field(..., description=\"Name of the artist\")\n",
    "    playlist_list_id: str = Field(..., description=\"Playlist's ID to which the song needs to be added\")\n",
    "    track_uri: Optional[str] = Field(None, description=\"Track URI returned by the search tool\")\n",
    "    all_playlist: List[PlaylistItem] = Field(default_factory=list, description=\"User's playlists\")\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def show_playlist():\n",
    "    # Create the model instance from the provided keyword arguments\n",
    "    \"\"\"Shows user's playlists and returns an updated Pydantic class with the list of playlists.\"\"\"\n",
    "\n",
    "    \n",
    "    playlist_list = []\n",
    "    \n",
    "    results = sp.current_user_playlists(limit=5)\n",
    "    while results:\n",
    "        if 'items' in results:\n",
    "            for playlist in results['items']:\n",
    "                playlist_list.append({\"name\": playlist['name'], \"id\": playlist['id']})\n",
    "            if results.get('next'):\n",
    "                results = sp.next(results)\n",
    "            else:\n",
    "                results = None\n",
    "        else:\n",
    "            results = None\n",
    "    \n",
    "    # Update the model with the fetched playlists\n",
    "    return playlist_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tool(\"search_song\", args_schema=ShowAllPlaylist, return_direct=True)\n",
    "def search_song_tool(**kwargs) -> str:\n",
    "    \"\"\"\n",
    "    Searches for a track using the song_name and artist_name provided in the ShowAllPlaylist\n",
    "    Pydantic model, then adds that track to the playlist using the target playlist's id stored in pydantic class ShowAllPlaylist.\n",
    "    \n",
    "    Returns a string message indicating whether the track was added successfully.\n",
    "    \"\"\"\n",
    "    # Build the Pydantic model instance from keyword arguments.\n",
    "    args = ShowAllPlaylist(**kwargs)\n",
    "    \n",
    "    # --- Step 1: Search for the track ---\n",
    "    try:\n",
    "        query = f\"track:{args.song_name} artist:{args.artist_name}\"\n",
    "        results = args._sp.search(q=query, type='track', limit=1)\n",
    "        tracks = results.get('tracks', {}).get('items', [])\n",
    "        track_uri = tracks[0]['uri'] if tracks else None\n",
    "        if not track_uri:\n",
    "            return f\"Could not find the track '{args.song_name}' by {args.artist_name}.\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error during search: {e}\")\n",
    "        return f\"Error during search: {e}\"\n",
    "    \n",
    "    # --- Step 2: Add the track to the playlist ---\n",
    "    try:\n",
    "        args._sp.playlist_add_items(args.playlist_list_id, [track_uri])\n",
    "        return f\"The song '{args.song_name}' by {args.artist_name} has been added to your playlist.\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding track: {e}\")\n",
    "        return f\"Error adding track: {e}\"\n",
    "\n",
    "    \n",
    "# TOOL 2 : USED BY THE LLM \n",
    "\n",
    "# from langchain_core.messages import ToolMessage\n",
    "# from langchain_core.tools import tool\n",
    "# import spotipy\n",
    "\n",
    "# from typing import Annotated\n",
    "# import spotipy\n",
    "# from langchain_core.messages import ToolMessage\n",
    "# from langchain_core.tools import tool\n",
    "# from langchain_core.tools.base import InjectedToolCallId\n",
    "\n",
    "\n",
    "\n",
    "# @tool(\"add_track_to_playlist\", args_schema=ShowAllPlaylist, return_direct=True)\n",
    "# def add_track_to_playlist_tool(\n",
    "#     *, \n",
    "#     tool_call_id: Annotated[str, InjectedToolCallId] = \"225789\",\n",
    "#     **kwargs\n",
    "# ) -> str:\n",
    "#     \"\"\"Adds the Song to the Playlist , by using \"\"\"\n",
    "#     # Build the Pydantic model instance from the provided keyword arguments.\n",
    "#     args = ShowAllPlaylist(**kwargs)\n",
    "#     try:\n",
    "#         # Use the private Spotify client from args (defined as _sp)\n",
    "#         args._sp.playlist_add_items(args.playlist_list_id, [args.track_uri])\n",
    "#         # Return a simple string result.\n",
    "#         return f\"The song {args.song_name} by {args.artist_name} has been added to your playlist.\"\n",
    "#     except spotipy.SpotifyException as e:\n",
    "#         error_message = f\"Error adding to playlist: {e}\"\n",
    "#         print(error_message)\n",
    "#         return error_message\n",
    "#     except Exception as e:\n",
    "#         error_message = f\"An error occurred: {e}\"\n",
    "#         print(error_message)\n",
    "#         return error_message\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIND LLM_WITH_TOOLS + CREATE_REACT_AGENT\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "tools = [show_playlist,search_song_tool]\n",
    "llm_with_tools= llm.bind_tools(tools=tools)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an assistant equipped with Spotify tools. You help users manage their playlists, search for songs, and add tracks to playlists. Follow the instructions carefully.Summarize your responses (even the ones from tool messages, in Natural Language Format and not JSON/dict Types.)\"),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "myagent = create_react_agent(model=llm_with_tools, tools=tools , state_schema=SpotifyState, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "PydanticJsonSchemaWarning: Default value <spotipy.client.Spotify object at 0x115d9ec50> is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
    "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
    "```\n",
    "\n",
    "the warning recieved above simply suggests, that it can't create a JSON serializable object for SP which is alright, since we only need it for runtime purpose\n",
    "additionally to exclude SP object from JSON schema, we can simply do an \"exclude=True\" this keeps the object at runtime, but doesn't parse it during deserilization for JSON structure of the args. \n",
    "this is why a JSON struct is required, for the LLM so that it can populate the tool_calls with the corresponding args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Can you show me all of my playlists?', additional_kwargs={}, response_metadata={}, id='51a41df5-e954-4dcd-a799-ae837bb9a815'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'show_playlists', 'arguments': '{\"song_name\": \"\", \"playlist_list_id\": \"\", \"query\": \"\", \"all_playlist\": [], \"artist_name\": \"\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-8342e465-8885-482f-8357-3d9f0c2121ca-0', tool_calls=[{'name': 'show_playlists', 'args': {'song_name': '', 'playlist_list_id': '', 'query': '', 'all_playlist': [], 'artist_name': ''}, 'id': '3c46a6b6-f3eb-4af8-bc0e-b46dce06c94a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 280, 'output_tokens': 18, 'total_tokens': 298, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content=\"query='' song_name='' artist_name='' playlist_list_id='' track_uri=None all_playlist=[{'name': 'Rap it up!!', 'id': '1hutKN3PVaquuA7PmS2Khm'}, {'name': 'Electronic', 'id': '5dO3GrkDYgeek1xTUd252i'}]\", name='show_playlists', id='bf1c00c7-f2d4-4237-b7b6-79d204a1ba7d', tool_call_id='3c46a6b6-f3eb-4af8-bc0e-b46dce06c94a')]}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
    "\n",
    "myagent.invoke({\"messages\": [(\"user\", \"Can you show me all of my playlists?\")]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'show_playlists', 'arguments': '{\"song_name\": \"\", \"playlist_list_id\": \"\", \"query\": \"\", \"artist_name\": \"\", \"all_playlist\": []}'}} ,....;  tool_calls=[{'name': 'show_playlists', 'args': {'song_name': '', 'playlist_list_id': '', 'query': '', 'artist_name': '', 'all_playlist': []}, 'id': '76657da3-8329-4c80-8f83-b44b11ab8cf7', 'type': 'tool_call'}], ...:\n",
    "```\n",
    "we got this error because the tool_call was generated :) but with a lot of other arguments from the pydantic model, which is not good\n",
    "so to fix that, we need to modify tool functions in a way, using (**kwargs) so that they access only the required fields from the model\n",
    "\n",
    "*INTERACTIVE CHAT LOOP BELOW:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive chat started (type 'exit' to quit):\n",
      "Assistant: Hello! How can I help you with your Spotify playlists today?\n",
      "Assistant: Here are your playlists: Rap it up!!, Electronic.  Is there anything else I can help you with?\n",
      "Assistant: The song 'butterfly effect' by Travis Scott has been added to your playlist.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage  # Import message types\n",
    "\n",
    "#defining the state obj as a dict so that it conforms to SpotifyState\n",
    "state: SpotifyState = {\n",
    "    \"messages\": [],\n",
    "    \"all_playlist\": [],\n",
    "    \"is_last_step\": False,\n",
    "    \"remaining_steps\": 10,  # or another appropriate integer\n",
    "    \"token\": None\n",
    "}\n",
    "\n",
    "print(\"Interactive chat started (type 'exit' to quit):\")\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in (\"exit\", \"quit\"):\n",
    "        break\n",
    "    \n",
    "    # Append the user's message to the state.\n",
    "    state[\"messages\"].append(HumanMessage(user_input))\n",
    "    \n",
    "    # Invoke your agent (which is built via create_react_agent)\n",
    "    updated_state = myagent.invoke(state)\n",
    "    \n",
    "    # Extract and print the latest AI message from the updated state.\n",
    "    latest_msg = updated_state[\"messages\"][-1]\n",
    "    if hasattr(latest_msg, \"content\") and latest_msg.content:\n",
    "        print(\"Assistant:\", latest_msg.content)\n",
    "    else:\n",
    "        print(\"Assistant: [No content returned]\")\n",
    "    \n",
    "    # Update state for the next iteration.\n",
    "    state = updated_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPROACH: 2\n",
    "Create show_playlists as a python function and pass its results , i.e. the all_playlist[] to the LLM in systemmessage, to set the persona for the LLM\n",
    "maybe we can create parallel nodes to solve this issue, \n",
    "ONE parallel node function that does, spotify authentication, and passes the sp token to the state\n",
    "in the other parallel node there's LLM calling, where it uses that token, and calls the tool, ( this time without pre-built components)\n",
    "```\n",
    "REFERENCES\n",
    "\n",
    "```\n",
    "\n",
    "https://python.langchain.com/docs/how_to/custom_chat_model/\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/how-tos/branching/#conditional-branchingz\n",
    "\n",
    "https://python.langchain.com/docs/how_to/tool_calling/\n",
    "\n",
    "https://python.langchain.com/docs/how_to/#prompt-templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNDERSTAND CONDITIONAL_EDGES SYNTAX: \n",
    "```\n",
    "add_conditional_edges(\n",
    "    current_node: str,\n",
    "    condition_function: Callable[[StateType], Sequence[str]],   #\n",
    "    possible_next_nodes: Sequence[str])   # list/tuple of all possible nodes that can be reached\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict, Annotated, Any\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.managed import IsLastStep\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "\n",
    "# Spotify Authentication\n",
    "\n",
    "SCOPE = \"playlist-modify-public playlist-read-private playlist-modify-private\"\n",
    "sp_oauth = SpotifyOAuth(\n",
    "    client_id=\"b8b719e778c2490fa3401ac44ef6c0d6\",  # Replace with your credentials\n",
    "    client_secret=\"e8f4d474f858432da3e4002eba2ab7fe\",\n",
    "    redirect_uri=\"http://localhost:8888/callback\",\n",
    "    scope=SCOPE,\n",
    ")\n",
    "sp = spotipy.Spotify(auth_manager=sp_oauth)\n",
    "\n",
    "\n",
    "# STATE INITIALISATION:\n",
    "\n",
    "class SpotifyState(TypedDict):\n",
    "    \n",
    "    messages : Annotated[list,add_messages]\n",
    "    all_playlist: list[dict]\n",
    "    is_last_step: IsLastStep\n",
    "    remaining_steps: Any\n",
    "\n",
    "\n",
    "#logic to display all playlist\n",
    "playlist_list = []\n",
    "\n",
    "results = _sp.current_user_playlists(limit=10)\n",
    "\n",
    "while results:  # Check if results is not None\n",
    "    if 'items' in results: #check if results has items key\n",
    "        for playlist in results['items']:\n",
    "            playlist_list.append({\"name\": playlist['name'], \"id\": playlist['id']})\n",
    "\n",
    "        if results['next']:\n",
    "            results = _sp.next(results)\n",
    "        else:\n",
    "            results = None  # Explicitly set results to None when done\n",
    "    else:\n",
    "        results = None #if there are no items key, set results to none to break the loop\n",
    "\n",
    "\n",
    "print(playlist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ISSUE : THIS DIDN'T WORK WITH \n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You're a helpful assistant, that shows User's Spotify Playlist and asks user which song to add?\"),\n",
    "    (\"human\", \"{input}\")\n",
    "    (\"tool\", )\n",
    "])\n",
    "system_msg = SystemMessage(content=\"You're a helpful assistant, that shows User's Spotify Playlist and asks user which song to add?\")\n",
    "human_msg = HumanMessage(content=\"Hello!!\")\n",
    "tool_msg= ToolMessage(content=playlist_list)\n",
    "\n",
    "result = graph.invoke({\"messages\": [system_msg,human_msg]})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPROACH 3:\n",
    "Manually create Tool Nodes and Apply Explicit Routing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HINTS AND REFERENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='hello!! Can you show me all of my playlists?' additional_kwargs={} response_metadata={} id='815abb5f-84be-4e78-af56-4c9621cd9aa7'\n",
      "content='' additional_kwargs={'function_call': {'name': 'show_playlist', 'arguments': '{}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-42f976a1-583d-4b02-9e68-7c15b80e41ad-0' tool_calls=[{'name': 'show_playlist', 'args': {}, 'id': 'd74ad18d-9477-4a09-bca9-018050285ab2', 'type': 'tool_call'}] usage_metadata={'input_tokens': 243, 'output_tokens': 3, 'total_tokens': 246, 'input_token_details': {'cache_read': 0}}\n",
      "content='Error: NameError(\"name \\'playlist_list\\' is not defined\")\\n Please fix your mistakes.' name='show_playlist' id='4e0a9287-03e6-4854-af4c-bf8412d096c1' tool_call_id='d74ad18d-9477-4a09-bca9-018050285ab2' status='error'\n",
      "content=\"There was an error retrieving your playlists.  The `show_playlist` function needs to be fixed.  It's currently returning an error.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-aa366c95-dfb9-48af-9544-c53f6afcd9ad-0' usage_metadata={'input_tokens': 271, 'output_tokens': 31, 'total_tokens': 302, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [(\"user\", \"hello!! Can you show me all of my playlists?\")]}\n",
    "for s in myagent.stream(inputs, stream_mode=\"values\"):\n",
    "        message = s[\"messages\"][-1]\n",
    "        print(message)\n",
    "#without actually making the show_playlist a node, you can't expect an update in State in state[]'all_playlist'] key\n",
    "# this is because, in python a function doesn't return a value until its called, \n",
    "# but how do we create another node, especially the starting node as show_playlist , along with using pre-buil create_react_agent?\n",
    "\n",
    "#APPROACH 1: \n",
    "# Since, we know that \"create_react_agent\" direcly creates a graph right? \n",
    "#well, there were never any restrictions on extending the graph with a node   JUST DO THIS :-      graph.add_node(\"show_playlist\", show_playlist) and it adds the node\n",
    "# additionally, you can make that newly added node as your START node as well, by adding the set_entry_point method\n",
    "\n",
    "#APPROACH 2: \n",
    "# to our problem can be, by running that function with the llm model, we basically invoke the llm inside that function, get an output w the help of llm\n",
    "# the output remains the same, i.e. all_playlist, but it'll be generated by the LLM, and it gets appended in the messages , so when we use create_react_agent as our GRAPH\n",
    "# we inherit the SpotifyState as well, in our graph, wherein inside the old messages we'll find our old data about playlists\n",
    "\n",
    "#APPROACH 3: \n",
    "# simply convert that into a tool as well, and train the llm using prompts how to handle multiple tool callls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.managed import IsLastStep\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "       (\"system\", \"Today is {today}\"),\n",
    "       (\"placeholder\", \"{messages}\"),]\n",
    ")\n",
    "\n",
    "class CustomState(TypedDict):\n",
    "    today: str\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    is_last_step: IsLastStep\n",
    "    \n",
    "graph = create_react_agent(model, tools, state_schema=CustomState, prompt=prompt)\n",
    "inputs = {\"messages\": [(\"user\", \"What's today's date? And what's the weather in SF?\")], \"today\": \"July 16, 2004\"}\n",
    "for s in graph.stream(inputs, stream_mode=\"values\"):\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
